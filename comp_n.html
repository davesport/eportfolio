<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> Competency N </title>
  <meta name="description" content="Website showcasing my progress, achievements, and lessons learned while in my MLIS program at San Jose State.">
  <link rel="stylesheet" media = "screen" href="css/style.css">
  <link rel="stylesheet" media = "print" href="css/print.css">

</head>
<body> 
    <div class="content-wrapper">
    <header class="banner"> 
    <h1> Competency N </h1>
    <h3> Sadie's E-Portfolio </h3>
    </header>
    <nav> 
        <ul class="navbar"> 
        <li class="navitem"> <a href="main.html"> Main page </a></li>
        <li class="navitem"> <a href="intro.html"> Introduction </a></li>
        <li class="navitem">  <a href="comp_a.html"> A </a></li>
        <li class="navitem">  <a href="comp_b.html"> B </a></li>
        <li class="navitem">  <a href="comp_c.html"> C </a></li>
        <li class="navitem">  <a href="comp_d.html"> D </a></li>
        <li class="navitem">  <a href="comp_e.html"> E </a></li>
        <li class="navitem">  <a href="comp_f.html"> F </a></li>
        <li class="navitem">  <a href="comp_g.html"> G </a></li>
        <li class="navitem">  <a href="comp_h.html"> H </a></li>
        <li class="navitem">  <a href="comp_j.html"> J </a></li>
        <li class="navitem">  <a href="comp_k.html"> K </a></li>
        <li class="navitem">  <a href="comp_l.html"> L </a></li>
        <li class="navitem">  <a href="comp_m.html"> M </a></li>
        <li class="navitem">  <a href="comp_n.html"> N </a></li>
        <li class="navitem">  <a href="comp_o.html"> O </a></li>
        <li class="navitem">  <a href="conclusion.html"> Conclusion </a></li>
        </ul>        
    </nav>
    <aside> 
        <h3> Competency N definition: </h3>
        <p> Evaluate programs and services using measurable criteria. </p> <br>

        <h3> Sections: </h3>
        <ul>
            <li>  <a href="#intro"> Introduction </a> </li>
            <li>  <a href="#evidence"> Evidence </a> </li>
            <li>  <a href="#conclusion"> Conclusion </a> </li>
            <li>  <a href="#references"> References </a> </li>
        </ul> <br>

        <h3> More information: </h3>
        <ul>
            <li>  <a href="index.html"> Main page </a></li>
            <li>  <a href="#footer"> Contact information </a>
        </ul>
    </aside>
    <main> 
        <h3 id="intro"> Introduction </h3>
        <p> Evaluating library programs and services is a necessary step in the information professional's position. However, it isn't enough to send patrons evaluation materials. There are specific strategies and guidelines that the information professional can follow in order to obtain responses that provide informative and measurable feedback that can improve the offered programs and services. </p>
        <p> For example, Choi et al. (2021) demonstrate in their study that the evaluation method can determine whether a person responds or not. In their study, adults responded to telephone and web-based surveys, rather than mailed surveys. Additionally, the pace of the evaluation cycle can change between seasonal, annual, one-time, and irregular. Choi et al. also measures other factors, including the layout, length, and wording of the evaluation method, and whether these aspects alter the evaluation's perceived ease of use and the responder's behavior. Meregaglia et al. (2021) studied a different aspect of evaluations. They found existing issues in how evaluations of staff members are standardized and distributed: "the absence of writen guidelines created confusion and perceived unfair variation in how annual evaluations [of librarian performance] were conducted" (p. 1). In the evidence section, I will demonstrate my current understanding of evaluation methods and how they should be conducted. </p>
        <p> Babbie (2012) discusses the types of information you can receive from evaluations: quantitative and qualitative data. WHen writing evaluation forms, it is important to have the desired type of information in mind. There are advantages to each kind of data. Quantitative data is more easily measurable to produce reliable statistics, while qualitative data can produce more nuanced results with users' emotion built into responses. Different situations may benefit from qualitative or quantitative data, and it is important to know the distinction between the two, and to write questions that produce the kind of data one wants to receive. Below, I explain why I've written questions specific ways, and how that creates an evaluation form that suits my needs. </p> <br>
        <h3 id="evidence"> Evidence </h3>
        <h4> 1) Survey Questionnaire </h4>
        <a href="includes/questionnaire.pdf"> <img src="images/quiz.png" style="width:150px; height:150px; display:block;"> INFO 285: Survey Questionnaire </a>
        <p> This is a group project I worked on in INFO 285: Research in Academic Libraries. We wrote a survey questionnaire with eight questions, which together told us: what professional development opportunities do different librarians have, and what opportunities would they like in the future? </p>
        <p> I created questions 1, 5 and 8 to be clear and easy-to-read. My group members wrote the other questions, a cover letter explaining the purpose and intent behind the questionnaire, and instructions for completing the questionnaire. We edited the questions together. Altogether, the goal was to create an unbiased method of obtaining participants' responses. Although this questionnaire has a different intent than feedback, the skills I learned in this gorup project are applicable to feedback forms, one of which I created and included below. </p> 
        <p> I wrote questions 1, 5 and 8 carefully, and phrased each to provide clarity without suggestion. These questions were difficult to write clearly while containing the information each question needed. Each question deliberately looks simple. This simplicity took hours to create. </p>
        <ul> 
            <li> Question 1 was difficult because I knew its response options needed to be as specific and inclusive as possible. By balancing the response options in two columns, and wording them similarly to show a few groupings, rather than seventeen different programs, the question is not overwhelming. </li> 
            <li> Question 5 was challenging because it asked for two responses in one question. To keep the question limited to a simple checkmark response, I created a table in which one checkmark could mark both the type of education (the row) and the usefulness of the education (the column). I also shaded the columns to create a clear line between rows, and centered the checkboxes in each box to make it easy to fill. </li>
            <li> Question 8 was different because I had two related items for participants to select, and had to organize the question responses to reflect these two items (type and subtype of a professional development opportunity). In question 5, I created a table for a two-pronged question. This time, in qeustion 8, I created a sub-question to further specify which opportunity types people want. I also had to ensure this question was full in scope, while still fitting on one page. </li>
        </ul> 
        <p> Together, my group and I had to plan the length and structure of the questionnaire overall. This questionnaire is long enough to yield sufficient quantitative data from its results, while still short enough for participants to complete without frustration. We also carefully spaced out our questionnaire so that there is only 1-2 questions per page, and each page has more white space than text. This is intentional, to make the questionnaire appear easy to fill out. Each question type was planned with the type of quantitative data needed: multiple choice, rank, and short-answer questions are best for producing quantitative data, and are easy to complete. The ultimate goal of this survey is to have a comprehensive </p> 
        <p> I included this piece of evidence to demonstrate my ability to create questions which produce measurable quantitative responses in evaluation surveys. <br>

        <h4> 2) Library presentation feedback form </h4> 
        <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSdoSXRPHd0GfYv69BERSxZ0ekW1nPUH9IxAy7tE3n1F6Z1GoQ/viewform?embedded=true" width="700" height="350" frameborder="0" marginheight="0" marginwidth="0">Loadingâ€¦</iframe> 
        <p> This is my Google form that I send professors after I conduct library presentations for their courses. I work at an academic library. I designed this Google form to encourage honest feedback on my presentations. This survey questionnaire is simpler than the one above, since my question (how did your library presentation go?) isn't as large in scope, and is for a much smaller group of people. I chose to make a Google form because it's free, easily shared with other people, and the responses are sent directly back to me. The questions I wrote ask participants to rank or measure the effectiveness of multiple items, including the use of technological devices, tools, and teaching strategies. I included optional, qualitative-response questions at the end in order to allow professors to write messages if they want to elaborate on their responses, or to simply share their thoughts with me. Since I only do a few presentations each semester, it is manageable for me to go through these responses and determine how they can inform my presentation improvement. </p>
        <p> To encourage honest and useful feedback, I carefully worded the description of the form to explain that I seek feedback for my own use, and so that I can improve my library instruction. Then in the questions, I separated myself from the subject of the question. I write: "your library professional" instead of "me." And finally, after the presentation is over and as I'm exiting the class, I tell the professor (quietly, and enthusiastically) that I'll send them an email with my presentation slides, as well as a link for feedback. This way, they expect the email and are more likely to respond. </p>
        <p> I included this piece of evidence to show that I can apply what I learn in the MLIS program to my work as a librarian. </p> <br>
        
        <h3 id="conclusion"> Conclusion </h3>
        <p> Effective evaluation is an important aspect of library services. Evaluation is a form of communication that ensures information professionals are providing useful, relevant, and informative services that suit their patrons' needs. Additionally, creating evaluation forms for patrons (or other population groups) to fill out gives these groups a voice, empowering them to speak up for what they want and need. Although evaluations serve an important purpose, it is essential that evaluation methods are carefully planned and created to suit each unique situation. Above, I shared two instances in which evaluation was needed, but resulted in very different evaluation forms. In the future, I plan to incorporate evaluation as a method of collecting patrons' experiences with my library services. I also hope to conduct research within librarianship in the future, and would plan to create questionnaires in order to collect data for a research study. </p><br>

        <h3 id="references"> References </h3>
        <p> Babbie, E. (2012). <i> The Practice of Social Research. </i> (13th ed.). Wadsworth Publishing. 
        <p> Choi, H., & Gyeongjui, J. (2021). Characteristics of measuring tools for assessing health information seeking behaviors in nationally representative surveys: Systematic review. <i> Journal of Medical Internet Research 23</i>(7). </p>
        <p> Meregaglia, A., Keyes, K., Vecchione, A., Armstrong, M., & Ruppel, M. (2021). Creating an annual evaluation framework for library faculty. <i> The Journal of Academic Librarianship 47.</i> 1-8. https://doi.org/10.1016/j.acalib.2021.102426 </p>
       
    </main>
    <footer id="footer"> 
        <h3> Contact me: </h3>
        <p> Feel free to email me at sadie.davenport@sjsu.edu </p>
    </footer>
</div>
</body>
